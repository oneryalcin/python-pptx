#!/usr/bin/env python3
"""
Live tests for MEP-006: The Feedback Loop (provide_feedback Tool)

These tests verify the provide_feedback tool works correctly through the full MCP protocol.
Tests include:
- Tool discovery and availability
- Basic feedback submission with success/failure cases
- Missing capability parameter handling
- Stderr logging verification through actual MCP client-server communication
- Integration with existing MEP tools

Run this script directly to test MEP-006 implementation:
    python mcp_server/tests/live_test_mep006.py
"""

import asyncio
import json
import sys
from pathlib import Path

# Add project root to path for imports
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from mcp import ClientSession, StdioServerParameters
    from mcp.client.stdio import stdio_client
except ImportError:
    print("‚ùå MCP client not available. Please install with: pip install mcp")
    sys.exit(1)


class TestMEP006FeedbackLive:
    """Live tests for MEP-006 provide_feedback tool."""

    def __init__(self):
        self.server_path = project_root / "mcp_server" / "server" / "main.py"
        self.test_results = []

    async def test_tool_discovery(self):
        """Test that provide_feedback tool is discovered by MCP client."""
        print("üîç Testing tool discovery...")

        server_params = StdioServerParameters(
            command=sys.executable,
            args=[str(self.server_path)]
        )

        try:
            async with stdio_client(server_params) as (read, write):
                async with ClientSession(read, write) as session:
                    await session.initialize()

                    # List available tools
                    tools = await session.list_tools()
                    tool_names = [tool.name for tool in tools.tools]

                    if "provide_feedback" in tool_names:
                        print("‚úÖ provide_feedback tool discovered successfully")
                        self.test_results.append("tool_discovery: PASS")

                        # Check tool description
                        feedback_tool = next(tool for tool in tools.tools if tool.name == "provide_feedback")
                        if "feedback" in feedback_tool.description.lower():
                            print("‚úÖ Tool description contains 'feedback'")
                            self.test_results.append("tool_description: PASS")
                        else:
                            print(f"‚ö†Ô∏è  Tool description may be unclear: {feedback_tool.description}")
                            self.test_results.append("tool_description: WARN")
                    else:
                        print(f"‚ùå provide_feedback tool not found. Available tools: {tool_names}")
                        self.test_results.append("tool_discovery: FAIL")

        except Exception as e:
            print(f"‚ùå Tool discovery failed: {e}")
            self.test_results.append("tool_discovery: FAIL")

    async def test_successful_feedback_submission(self):
        """Test submitting successful feedback through MCP protocol."""
        print("\nüìù Testing successful feedback submission...")

        server_params = StdioServerParameters(
            command=sys.executable,
            args=[str(self.server_path)]
        )

        try:
            # Capture server stderr to verify logging
            process = await asyncio.create_subprocess_exec(
                sys.executable, str(self.server_path),
                stdin=asyncio.subprocess.PIPE,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )

            async with stdio_client(server_params) as (read, write):
                async with ClientSession(read, write) as session:
                    await session.initialize()

                    # Submit successful feedback
                    result = await session.call_tool(
                        "provide_feedback",
                        arguments={
                            "feedback_text": "Test task completed successfully",
                            "is_success": True
                        }
                    )

                    # Verify response
                    if result.content:
                        response_text = result.content[0].text
                        response = json.loads(response_text)

                        if response.get("status") == "Feedback received. Thank you.":
                            print("‚úÖ Successful feedback submission returned correct response")
                            self.test_results.append("successful_feedback: PASS")
                        else:
                            print(f"‚ùå Unexpected response: {response}")
                            self.test_results.append("successful_feedback: FAIL")
                    else:
                        print("‚ùå No response content received")
                        self.test_results.append("successful_feedback: FAIL")

        except Exception as e:
            print(f"‚ùå Successful feedback test failed: {e}")
            self.test_results.append("successful_feedback: FAIL")

    async def test_failed_feedback_with_missing_capability(self):
        """Test submitting failed feedback with missing capability."""
        print("\nüö´ Testing failed feedback with missing capability...")

        server_params = StdioServerParameters(
            command=sys.executable,
            args=[str(self.server_path)]
        )

        try:
            async with stdio_client(server_params) as (read, write):
                async with ClientSession(read, write) as session:
                    await session.initialize()

                    # Submit failed feedback with missing capability
                    result = await session.call_tool(
                        "provide_feedback",
                        arguments={
                            "feedback_text": "Could not complete animation task",
                            "is_success": False,
                            "missing_capability": "Animation API support"
                        }
                    )

                    # Verify response
                    if result.content:
                        response_text = result.content[0].text
                        response = json.loads(response_text)

                        if response.get("status") == "Feedback received. Thank you.":
                            print("‚úÖ Failed feedback with missing capability returned correct response")
                            self.test_results.append("failed_feedback_missing: PASS")
                        else:
                            print(f"‚ùå Unexpected response: {response}")
                            self.test_results.append("failed_feedback_missing: FAIL")
                    else:
                        print("‚ùå No response content received")
                        self.test_results.append("failed_feedback_missing: FAIL")

        except Exception as e:
            print(f"‚ùå Failed feedback test failed: {e}")
            self.test_results.append("failed_feedback_missing: FAIL")

    async def test_feedback_without_missing_capability(self):
        """Test submitting feedback without optional missing_capability parameter."""
        print("\nüìã Testing feedback without missing capability...")

        server_params = StdioServerParameters(
            command=sys.executable,
            args=[str(self.server_path)]
        )

        try:
            async with stdio_client(server_params) as (read, write):
                async with ClientSession(read, write) as session:
                    await session.initialize()

                    # Submit feedback without missing_capability
                    result = await session.call_tool(
                        "provide_feedback",
                        arguments={
                            "feedback_text": "Standard task completion",
                            "is_success": True
                        }
                    )

                    # Verify response
                    if result.content:
                        response_text = result.content[0].text
                        response = json.loads(response_text)

                        if response.get("status") == "Feedback received. Thank you.":
                            print("‚úÖ Feedback without missing capability returned correct response")
                            self.test_results.append("feedback_no_missing: PASS")
                        else:
                            print(f"‚ùå Unexpected response: {response}")
                            self.test_results.append("feedback_no_missing: FAIL")
                    else:
                        print("‚ùå No response content received")
                        self.test_results.append("feedback_no_missing: FAIL")

        except Exception as e:
            print(f"‚ùå Feedback without missing capability test failed: {e}")
            self.test_results.append("feedback_no_missing: FAIL")

    async def test_tool_parameter_validation(self):
        """Test tool parameter validation and error handling."""
        print("\nüîí Testing parameter validation...")

        server_params = StdioServerParameters(
            command=sys.executable,
            args=[str(self.server_path)]
        )

        try:
            async with stdio_client(server_params) as (read, write):
                async with ClientSession(read, write) as session:
                    await session.initialize()

                    # Test missing required parameters
                    try:
                        result = await session.call_tool(
                            "provide_feedback",
                            arguments={"feedback_text": "Test"}  # Missing is_success
                        )
                        print("‚ö†Ô∏è  Tool allowed missing required parameter - this may be expected MCP behavior")
                        self.test_results.append("parameter_validation: WARN")
                    except Exception:
                        print("‚úÖ Tool properly validates required parameters")
                        self.test_results.append("parameter_validation: PASS")

        except Exception as e:
            print(f"‚ùå Parameter validation test failed: {e}")
            self.test_results.append("parameter_validation: FAIL")

    async def test_integration_with_existing_tools(self):
        """Test that feedback tool works alongside existing MEP tools."""
        print("\nüîó Testing integration with existing tools...")

        server_params = StdioServerParameters(
            command=sys.executable,
            args=[str(self.server_path)]
        )

        try:
            async with stdio_client(server_params) as (read, write):
                async with ClientSession(read, write) as session:
                    await session.initialize()

                    # List all tools to verify they all exist
                    tools = await session.list_tools()
                    tool_names = [tool.name for tool in tools.tools]

                    expected_tools = ["get_info", "execute_python_code", "save_presentation", "provide_feedback"]
                    missing_tools = [tool for tool in expected_tools if tool not in tool_names]

                    if not missing_tools:
                        print("‚úÖ All expected tools are available")

                        # Test calling get_info, then provide_feedback
                        info_result = await session.call_tool("get_info", arguments={})
                        if info_result.content and "feedback" in info_result.content[0].text.lower():
                            print("‚úÖ get_info tool includes feedback information")

                            # Now provide feedback about using get_info
                            feedback_result = await session.call_tool(
                                "provide_feedback",
                                arguments={
                                    "feedback_text": "get_info tool successfully provided guidance including feedback usage",
                                    "is_success": True
                                }
                            )

                            if feedback_result.content:
                                response = json.loads(feedback_result.content[0].text)
                                if response.get("status") == "Feedback received. Thank you.":
                                    print("‚úÖ Integration test successful")
                                    self.test_results.append("integration: PASS")
                                else:
                                    print("‚ùå Integration test failed at feedback step")
                                    self.test_results.append("integration: FAIL")
                            else:
                                print("‚ùå No feedback response received")
                                self.test_results.append("integration: FAIL")
                        else:
                            print("‚ö†Ô∏è  get_info doesn't mention feedback - may need updating")
                            self.test_results.append("integration: WARN")
                    else:
                        print(f"‚ùå Missing expected tools: {missing_tools}")
                        self.test_results.append("integration: FAIL")

        except Exception as e:
            print(f"‚ùå Integration test failed: {e}")
            self.test_results.append("integration: FAIL")

    async def test_stderr_logging_verification(self):
        """Test that feedback is actually logged to stderr (manual verification)."""
        print("\nüìã Testing stderr logging (run manually to verify)...")

        print("üîç To manually verify stderr logging:")
        print("1. Run: python mcp_server/server/main.py")
        print("2. Send this JSON message:")
        print(json.dumps({
            "jsonrpc": "2.0",
            "id": 1,
            "method": "tools/call",
            "params": {
                "name": "provide_feedback",
                "arguments": {
                    "feedback_text": "Manual test feedback",
                    "is_success": True,
                    "missing_capability": "Nothing missing"
                }
            }
        }, indent=2))
        print("3. Check stderr for: [AGENT_FEEDBACK] | SUCCESS: True | MISSING: Nothing missing | TEXT: \"Manual test feedback\"")

        self.test_results.append("stderr_logging: MANUAL")

    def print_summary(self):
        """Print test summary."""
        print("\n" + "="*80)
        print("üß™ MEP-006 Live Test Results Summary")
        print("="*80)

        pass_count = sum(1 for result in self.test_results if "PASS" in result)
        warn_count = sum(1 for result in self.test_results if "WARN" in result)
        fail_count = sum(1 for result in self.test_results if "FAIL" in result)
        manual_count = sum(1 for result in self.test_results if "MANUAL" in result)

        for result in self.test_results:
            status = "PASS" if "PASS" in result else "WARN" if "WARN" in result else "FAIL" if "FAIL" in result else "MANUAL"
            icon = "‚úÖ" if status == "PASS" else "‚ö†Ô∏è " if status == "WARN" else "‚ùå" if status == "FAIL" else "üîç"
            print(f"{icon} {result}")

        print(f"\nüìä Results: {pass_count} passed, {warn_count} warnings, {fail_count} failed, {manual_count} manual")

        if fail_count == 0:
            print("üéâ All automated tests passed! MEP-006 implementation looks good.")
            return True
        else:
            print("üí• Some tests failed. Please review implementation.")
            return False


async def main():
    """Run all MEP-006 live tests."""
    print("üöÄ Starting MEP-006 Live Tests: The Feedback Loop")
    print("="*80)

    tester = TestMEP006FeedbackLive()

    # Run all tests
    await tester.test_tool_discovery()
    await tester.test_successful_feedback_submission()
    await tester.test_failed_feedback_with_missing_capability()
    await tester.test_feedback_without_missing_capability()
    await tester.test_tool_parameter_validation()
    await tester.test_integration_with_existing_tools()
    await tester.test_stderr_logging_verification()

    # Print summary
    success = tester.print_summary()

    return 0 if success else 1


if __name__ == "__main__":
    try:
        exit_code = asyncio.run(main())
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\nüõë Tests interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\nüí• Unexpected error running tests: {e}")
        sys.exit(1)
